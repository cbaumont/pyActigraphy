{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8596b804",
   "metadata": {},
   "source": [
    "# Introduction to the \"light\" exposure data module of pyActigraphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d00d9",
   "metadata": {},
   "source": [
    "> There shall be light!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dc0ac",
   "metadata": {},
   "source": [
    "![There shall be light!](img/jonathan-borba-3eC5n6gHwe8-unsplash.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118f28b",
   "metadata": {},
   "source": [
    "Photo by <a href=\"https://unsplash.com/@jonathanborba?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Jonathan Borba</a> on <a href=\"https://unsplash.com/s/photos/sun-light?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8021b24",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "The development of the pyActigraphy module for analysing light exposure data was led and financially supported by members of the Daylight Academy Project *The role of daylight for humans* (led by Mirjam MÃ¼nch, Manuel Spitschan). The module is part of the Human Light Exposure Database. For more information about the project, please see\n",
    "https://daylight.academy/projects/state-of-light-in-humans/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7995b9",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Many actigraphy devices also record light exposure data. As light is a strong *zeitgeber*, it is likely that any circadian analysis, if light itself is not its primary focus, will at least control for interindividual differences in light exposure.\n",
    "\n",
    "This is where the \"light\" module of pyActigraphy comes into play. It provides access to light exposure data recorded by several devices and light-specific metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0963827",
   "metadata": {},
   "source": [
    "This first introduction tutorial presents how to:\n",
    "\n",
    "* access light exposure data from various actigraphy devices\n",
    "* visualize light exposure data using the [plotly](https://plotly.com/python/) package\n",
    "\n",
    "**NB(1)**: there are many visualization packages available in Python ([matplotlib](https://matplotlib.org), [seaborn](https://seaborn.pydata.org), [plotly](https://plotly.com/python/), etc). Feel free to use the one you like the most. Plotly is used here for convenience as it is part of *pyActigraphy* dependencies and thus automatically installed when installing pyActigraphy.\n",
    "\n",
    "**NB(2)**: by default, the light exposure data are automatically log-transformed (log10+1) upon reading the recording with *pyActigraphy*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5207e7",
   "metadata": {},
   "source": [
    "## How to get some help?\n",
    "\n",
    "In pyActigraphy, the inline documentation of a variable or a function can easily be access through the `help` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8949625",
   "metadata": {},
   "source": [
    "## Imports and input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a039f5",
   "metadata": {},
   "source": [
    "First, let's import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b71b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyActigraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8508848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a31b5",
   "metadata": {},
   "source": [
    "Now, in the context of this tutorial, we will use as input data a sample file recorded by a ActTrust device (Condor Instrument), located in the test directory of the pyActigraphy package itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(\n",
    "    os.path.dirname(pyActigraphy.__file__),\n",
    "    'tests','data',\n",
    "    'test_sample_atr.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820d096",
   "metadata": {},
   "source": [
    "Reading such a file with pyActigraphy is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf06e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pyActigraphy.io.read_raw_atr(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66af6d6",
   "metadata": {},
   "source": [
    "For more information about the various file formats that can be read by pyActigraphy or about the information that can be retrieved via this `raw` object, please see this [tutorial](https://ghammad.github.io/pyActigraphy/pyActigraphy-Intro.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15dd96f",
   "metadata": {},
   "source": [
    "## How to access light exposure data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4d1c5",
   "metadata": {},
   "source": [
    "Light exposure data can be accessed through the `light` attribute of the `raw`object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c236fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.light"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2e124",
   "metadata": {},
   "source": [
    "This command returns an object (`LightRecording`) that both contains the light exposure data and gives you access to various light-specific metrics. More information about the [`LightRecording`](https://ghammad.github.io/pyActigraphy/LightRecording.html) class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92d87c",
   "metadata": {},
   "source": [
    "Some devices record light data via different sensors, providing thus multiple channels. To see the list of available channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93229e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.light.get_channel_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e387215f",
   "metadata": {},
   "source": [
    "In this example case, multiple light channels are available. To access the light data, it is possible to either get a single channel directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.light.get_channel('RED LIGHT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c3d1c",
   "metadata": {},
   "source": [
    "Or get multiple channels at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.light.get_channels(['RED LIGHT', 'GREEN LIGHT', 'BLUE LIGHT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01118e9",
   "metadata": {},
   "source": [
    "Or access the underlying data ([pandas.DataFrame](https://pandas.pydata.org/docs/reference/frame.html)) and select the requested channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c208fc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw.light.data.loc[:,['UVA LIGHT','UVB LIGHT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924746e8",
   "metadata": {},
   "source": [
    "**NB**: remember that, in both cases, the light exposure data are automatically log-transformed (log10+1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966f543",
   "metadata": {},
   "source": [
    "## How to visualize light exposure data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cf45e",
   "metadata": {},
   "source": [
    "In this tutorial, the python package \"plotly\" is used to display graphics. However, feel free to use your favourite graphic library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3114ba1",
   "metadata": {},
   "source": [
    "First, let's create the graphic layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eba708",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    title=\"Light exposure data\",\n",
    "    xaxis=dict(title=\"Date time\"),\n",
    "    yaxis=dict(title=\"$log_{10}(\\mathrm{Light~intensity})+1~\\mathrm{[microwatt/cm^2]}$\"),\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2da618",
   "metadata": {},
   "source": [
    "And plot the (red) light data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0fce5d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig1 = go.Figure(\n",
    "    data=[go.Scatter(\n",
    "        x=raw.light.get_channel('RED LIGHT').index.astype(str),\n",
    "        y=raw.light.get_channel('RED LIGHT'),\n",
    "        name='Red light')\n",
    "    ],\n",
    "    layout=layout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d91e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ee701",
   "metadata": {},
   "source": [
    "Since all the recorded light channels are readily available, displaying multiple channels is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.update(showlegend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d77ea0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "fig2 = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=raw.light.get_channel('RED LIGHT').index.astype(str),\n",
    "            y=raw.light.get_channel('RED LIGHT'),\n",
    "            name='Red light',\n",
    "            line={'color':'red'}\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=raw.light.get_channel('BLUE LIGHT').index.astype(str),\n",
    "            y=raw.light.get_channel('BLUE LIGHT'),\n",
    "            opacity=.75,\n",
    "            name='Blue light',\n",
    "            line={'color':'blue'}\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=raw.light.get_channel('GREEN LIGHT').index.astype(str),\n",
    "            y=raw.light.get_channel('GREEN LIGHT'),\n",
    "            opacity=.5,\n",
    "            name='Green light',\n",
    "            line={'color':'green'}\n",
    "        )\n",
    "    ],\n",
    "    layout=layout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037486f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38ebdf",
   "metadata": {},
   "source": [
    "Et voilÃ ! For now..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyActi37",
   "language": "python",
   "name": "pyacti37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
